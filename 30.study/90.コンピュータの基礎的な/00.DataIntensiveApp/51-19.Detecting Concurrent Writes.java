■■■■■■■■■■■■■■■■■■■■■■■■■■ Detecting Concurrent Writes
Dynamo-style databases では、複数のクライアントが、
同じキーに対し、
同時書き込みすることを許している。
結果、
strict quorum が使われていたとしても、コンフリクトは発生しうる。

この点、multi-leader replication と似ている。
ただ、Dynamo-style databases は、
read repair or hinted handoff
の最中でも発生しうる。

問題は、
イベントが、異なるノードには異なる順番で到着するかもしれないってこと。
なぜか
経路ごとにネットワーク遅延の度合いが異なったり、
部分的に fail が発生したりするかもしれんから。

例)
クライアントAとBとがいる。
それぞれ、キー X に対する書き込みを、3つのノードに対して行うとする。

・ノード1 は A からの書き込みを受け取る
しかし、
B からのある書き込みは、一時的機能停止のため決して決して受け取られないとする。

・ノード2 は A からの書き込みを最初に受け取る。
次に、Bからの書き込みを受け取る。

・ノード3 は B からの書き込みを最初に受け取る。
次に、Aからの書き込みを受け取る。

もし、各ノードがそのキーの値を、クライアントから書き込みリクエストを受け取るたび単純に上書きした場合、
ノードたちは永久に inconsistent になる。

・ノード2 は X の最終的値は B だと認識する。
他のノードは、最終的値はA だと認識する。

▼ eventually consistent になるために
・レプリカたちは、同じ値に収束させていかなくてはならない。
どうやって？
レプリケートされたDBたちが自動的にしてくれる？
残念ながら、ほとんどの実装は、そこらへん貧弱だ。

・データ欠損を避けたい場合、
アプリ開発者は、DBのコンフリクトハンドリングの内部の動きについて、多くのことを知っておかなくてはならない。

■■■■■■■■■■■■■■■■■■■■■■■■■■ Last write wins (discarding concurrent writes)
・一つのアプローチ
各レプリカは最新の値のみを格納するべきであり、
古い値は上書きされ、消えてなくなることを許容することとする。

どの書き込みが"最新"であるか。
それを判定する明確な方法がある限り、
そして、
全ての書き込みが、最終的に全てのレプリカにコピーされる限り、
レプリカは最終的には同じ値に収束する。
とはいえ、
このアイデアはミスリーディングだ。
同時書き込みがなされるとき、
あるクライアントは他のクライアントが、書き込みリクエストをDBはノードにいつ送るのかを知らない。
よって、
どちらの書き込みが先になされたかは、不明確である。

▼ 順番はタイムスタンプで。
書き込みにしかるべき順序がなくても、
任意の順序を強制することはできる。
各書き込みにタイムスタンプをつけて、
より大きいタイムスタンプを最新とする。
で、より早いタイムスタンプの書き込みを破棄する。
 →last write wins (LWW)
LWW はCassandra でサポートされている唯一のコンフリクト解決メソッドであり、
Riak ではオプションとなっている。

▼ LWW は耐久性を犠牲にする
複数の書き込みが同じキーに対してなされたとする。
それら全て、成功としてクライアントに伝わったとしても、
一つの書き込みだけが生き残り、
他の書き込みたちは破棄される。
さらにいうと、
LWW は同時になされてすらいない書き込みを破棄してしまう可能性もある。
// タイムスタンプちゃんと取れているんか問題の結果かな？

・書き込みのロストが許容されるユースケースもある。
// キャッシングとか
もし、書き込みロストが許容できない場合、コンフリクト解決に LWW は使えない。

・LWW を使ったDB を使う唯一の安全な方法は、
キーは一度だけしか書き込みがなされないことを保証し、
以降はそのキーを immutable として扱う方法だ。
こうして、
同じキーに対する同時交信は回避できる。

▼ Cassandra の推奨される使用方法
UUIDをキーとして使う
で、各書き込みにユニークなキーを付与する。

■■■■■■■■■■■■■■■■■■■■■■■■■■ The “happens-before” relationship and concurrency
どうやって、2つの操作が同時に起きたかどうかを判断するのだ？
例)
Bの値更新が、Aによって挿入された値に対してなされたとき、
Aの操作はBの操作より前になされたと、同時になされていないと言える。
We also say that B is causally dependent on A.

例)
Figure 5-12
2つのクライアントは、もう一方のクライアントが同じキーに対して操作を行ったことを知らない。
Thus, there is no causal dependency between the operations.

操作A は 操作B より前になされたと言えるケース
B が A について知っている場合
A に依存している場合
or builds upon A in some way.

・ある操作が他の操作より前に発生したかどうかが、
what concurrency means
を定義するキーとなる。
どちらも相手より先に発生していない、ということが言えるならば、その操作は同時発生だと言える。
(i.e., neither knows about the other)

・このように、2つの操作 A と B があるとき、3つの可能性がある。
either A happened before B,
or B happened before A,
or A and B are concurrent.

・私達に必要なのは、2つの操作が同時になされたかどうかを判別するアルゴリズムだ。
もしある操作が他の操作よりなされた場合、
あとの操作は先の操作を上書きすべき。
そして、
ある操作が同時になされたときには、
そのコンフリクトを解決しなければならない。

■■■■■■■■■■■■■■■■■■■■■■■■■■ Concurrency, Time, and Relativity
・2つの操作が concurrent かどうかを決めるのに、
それら操作が文字通り時間的に重なっていたかどうかは重要ではない。

分散システムにおける clock 問題があるがために、
2つの出来事が正確に同じ時間に発生したかどうかを判別するのは極めて難しい。

▼ Cuncurrency とは！
・正確な時間はどうでもいい
それぞれの操作が、相手の事に気づいていない場合、それぞれの操作は concurrent だと定義する。
・具体的な時間はどうでもいい
・このことは、特殊相対性理論としばしば結び付けられる。
 information cannot travel faster than the speed of light.

two events that occur some distance apart
cannot possibly affect each other
 if the time between the events
 is shorter than the time it takes light
 to travel the distance between them.

ネットワークに遅延が発生、または中断されていた場合、
2つの操作が異なる時間に発生したとしても、それらは concurrent である。
なぜなら、
ネットワークの問題によって、ある操作がもう一方の操作のことを知りえない状況だったから。

■■■■■■■■■■■■■■■■■■■■■■■■■■ Capturing the happens-before relationship
▼ concurrent かどうかを判断するアルゴリズム

・レプリカが一つしかないDBを例に考える
// シンブルレプリカでの動きが理解できれば、複数のレプリカがあるリーダーレスDBに一般ができる
二人のクライアントが、同一のカートに、同時にアイテムを追加していくとする。// いかれた例だが。
・初期状態は、カートは空。

-------------------------------------------------
1. クライアント1は、[milk]をカートに追加する。
サーバはそれをDBに格納する。
格納成功。バージョン番号1とともに、サーバーは値をクライアントに返す。

2. クライアント2は[eggs]をカートに追加する。
クライアント2は、クライアント1が[milk]を追加したことを知らない。
カートには[eggs]しかないと考えている。
サーバはこの書き込みにバージョン2を割り当てる。
[milk]と[eggs]とを、別々の値としてDBに格納する。
サーバは2つの値とバージョン番号とをクライアントに返す。


3. クライアント1 は クライアント2 の書き込みに気づかない。
[flour]をカートに追加しようとする。
クライアント1 は、カートの中身は[milk, flour]だと考えている。
この値は、バージョン番号1とともにサーバに送られる。

サーバーは、バージョン番号から、[milk, flour]がバージョン1の以前の書き込み[milk] に取って代わること、
しかし、この値は[eggs] と concurrentであるということを判断できる。
そして、
サーバーは[milk, flour]にバージョン番号 3 を割り当てる。
それによって、バージョン 1 の値を上書きする。
しかし、
バージョン 2 の [eggs] を保持する。
そして、
クライアントに(上書きされずに残っている)[milk, flour]と[eggs]とを返す。



4. 一方その頃、クライアント2 はカートに [ham] を追加しようとする。
クライアント1 がカートに [flour] を入れたことには気づいていない。
クライアント 2 は、最後のレスポンスから[milk] and [eggs]を受け取っていた。
なので、それとハムとをマージして[eggs, milk, ham]が最新の値となる。
クライアント 2 は[eggs, milk, ham] を、バージョン番号 2 とともに送る。
サーバはバージョン番号 2 が[eggs] を上書きすることを検知する。
そして、その処理が[milk, flour] と concurrentだということも検知する。
で、残っている値は、
[milk, flour] with version 3,
and [eggs, milk, ham] with version 4.

5. クライアント 1 は[bacon]をカートに追加する。
事前にバージョン番号 3 で[milk, flour] and [eggs] を受け取っていたので、
それをマージして[milk, flour, eggs, bacon] となる。
それをバージョン番号 3 でサーバに送る
これは[milk, flour] を上書きする。
そして[eggs, milk, ham]と concurrentなので、両方の値が保持される。
-------------------------------------------------
上記例では、クライアントたちは最後までサーバ上のデータと UpToDate になっていない。
なぜか
つねに他の操作が 同時に行われているから。
しかし、古いバージョンの値は最終的に上書きされるので、書き込みがロストすることはない。

▼ サーバは操作が concurrent かどうか判断できている
何によって？
バージョン番号によって。
そしてそれは値に翻訳される必要はないので、どんなデータ構造でも問題ない

▼ 上記アルゴリズム
・サーバーは全てのキーのバージョン番号を保守している。
キーに書き込みがなされると、その番号をインクリメントする
 →新しい番号を書かれた値と一緒に格納する。

・クライアントがキーを読み込む
 →サーバはまだ上書きがなされていない全ての値を、バージョン番号と一緒に返す
  →クライアントは書き込みをする前に、キーを読み込まなければならない。

・クライアントが書き込みをするとき、前回の読み込み時のバージョン番号を含めなければならない。
そして、
すべての値を前回の読み込み時に受け取ったものとマージしなければならない
※ 書き込みリクエストのレスポンスは、全ての現在の値の読み込みでもある。
  結果、複数の書き込みを連結することができる。

・サーバがクライアントから、バージョン番号とともに書き込みを受け取ったとき、
そのバージョン番号または、その下位の番号を上書きすることができる。
(since it knows that they have been merged into the new value),
しかし
より高いバージョン番号のすべての値はほじしなければならない。
(because those values are concurrent with the incoming write).

書き込みに、前回読み込み時のバージョン番号が含まれる場合、
その書き込みがどのバージョンの状態に基づいたものなのかが判断できる。
バージョン番号なしで書き込みをした場合、
他のすべての値と concurrent ということになる。
よって、
その書き込みは何も上書きしない
 —it will just be returned as one of the values on subsequent reads.

■■■■■■■■■■■■■■■■■■■■■■■■■■ Merging concurrently written values
上記アルゴリズムは、知らないうちにドロップされるデータはないことが保証される。
しかし、
クライアントにいくつかの処理を要求することになる。

もし、
複数の操作が同時に発生したならば、
クライアントはその後で
同時に書かれた値をマージすることでクリーンアップしなければならない。
※ Riak はこれら concurrent な値のことを siblings と呼んでいる。

シブリング をマージするのは、本質的にマルチリーダーレプリケーションのコンフリクト解決と同じ。
シンプルなアプローチは、
バージョン番号やタイムスタンプに基づいて一つの値を選択することだが、それだとデータがロストする可能性がある。
それをさけるためには、
アプリ側のコードでうまいことやる必要がある。

ショッピングカートの例でいくと、
シブリングをマージする合理的なアプローチは、
just take the union.
最終的な2つのシブリングは
[milk, flour, eggs, bacon] and [eggs, milk, ham]
だった。
ここで、ミルクと卵は双方にある。いずれも一度の書き込みがなされただけなのに。
こいつらがマージされ、冗長部分が取り払われると
[milk, flour, eggs, bacon, ham]
になる。

しかしながら、
カートについかするだけではなく、削除もするとなると、
シブリングを union するだけだと、正しい結果は得られないかもしれない。
2つのシブリングカートがマージされ、
一方のカートからのみアイテムが削除されたら、
削除されたアイテムは、in the union of the siblings にまた現れることになる。

▼ tombstones
上記問題を防ぐために
アイテムはただDBから削除される、だけではあたり内
そのかわり
システムはバージョン番号とともにマーカーを残さなければならない。
で、そのマーカーは、
シブリングがマージされる時に、そのアイテムが削除されることを示す。
そういったマーカーのことを tombstones と呼ぶ

アプリのコード側でシブリングのマージを行うと、
複雑になり、エラーが入り込む可能性があるので、
Automatic Conflict Resolution のように、
データストラクチャーとしてこのマージを自動的にできるような設計努力がなされていたりする。

▼ CRDTs というデータストラクチャーファミリーをサポート
Riak がサポート。
シブリングを自動マージする including preserving deletions.

■■■■■■■■■■■■■■■■■■■■■■■■■■ Version vectors
上記例では、レプリカ一つのケースを考えていた。
では、マルチレプリカで、ノーリーダーの場合、
アルゴリズムはどう変わってくるだろうか？

複数のレプリカが書き込みを同時に受け付ける場合、バージョン番号一つだけでは不十分となる。

▼ Version vectors
そのかわり
レプリカごとに、そしてキーごとに、バージョン番号が必要となる。
各レプリカは、書き込み処理を行う際に自身のバージョン番号をインクリメントする
かつ、
他のレプリカたちを見たときの各バージョン番号も追跡する。
この情報を持って、
どの値が上書き対象で、どの値がシブリングとして保持するかを判断する。

全てのレプリカから集まったバージョン番号たちのことを、Version vectors と呼ぶ。
Version vectors 系のアイデアは複数あるが、
Riak 2.0 で使われている
the dotted version vector
が面白いらしいが、深くは語られない。

バージョンベクターは、値が読み込まれるタイミングで、DBレプリカからクライアントに送られる。
そして、値が続いて書き込まれるタイミングで、
DBに送り返される
(Riak encodes the version vector as a string that it calls causal context.)

バージョンベクターによって、DBは、上書きか、concurrent な書き込みかを判別する。

シングルレプリカの例のように、
アプリ側でシブリングをマージしなければならない。

バージョンベクターのストラクチャーは
一つのレプリカから読み込んで、
続く書き込みを別のレプリカにお繰り返しても、問題ない事を保証している。
結果、シブリングが生成されるかもしれないが、
シブリングが正しくマージされる限り、データはロストしない。

■■■■■■■■■■■■■■■■■■■■■■■■■■ Version vectors and vector clocks
バージョンベクターは、ベクタークロックと呼ばれることもある。
両者は異なるものであるにもかかわらず。
違いはなにか。
レプリカの状態を確認する際、
version vectors are the right data structure to use.
