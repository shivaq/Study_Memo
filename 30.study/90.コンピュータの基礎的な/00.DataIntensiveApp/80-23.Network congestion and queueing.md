### Network congestion and queueing
#### 渋滞の度合いが車旅行の時間を左右するように
* When driving a car, travel times on road networks often vary most due to traffic congestion.

#### キューの度合いがネットワークの遅延を左右する
* Similarly, the variability of packet delays on computer networks is most often due to queueing


#### ▼ ネットワークスイッチでキュー
* 複数の異なるノードが、同時に同じ宛先にパケットを送った場合  
ネットワークスイッチはパケットをキューして  
そのキューを the destination network link に一つずつ渡していく。
* ビジーなネットワークリンクでは、until it can get a slot パケットは待たなければならないかもしれない。
これを、network congestion と呼ぶ。
* もしスイッチのキューがいっぱいになるくらいたくさんのデータがやってきたら、  
あふれたパケットはドロップする。そしたらそいつらは再送信しなければならない。
たとえ、ネットワークに問題がなかったとしても。

![alt Figure8-2](/Users/yasuakishibata/Google_Drive/Referenced_by_markdown/skdfjkasfdj.png)

#### ▼ OS でキュー
* パケットが宛先のマシンに到達したとき、全てのCPUコアがビジーだった場合、  
ネットワークからのやってくるリクエストは OS によってキューされる。  
until the application is ready to handle it.   

####  仮想環境の VM がキュー
* 仮想環境では、OSは 数十秒とまったりする。他のマシンがCPU コアを使っている間。  
この間、VM はネットワークからのデータを処理できない。  
よって、やってくるデータは the virtual machine monitor によってキュー(バッファ) される。

#### congestion avoidance or backpressure
* TCP もフローコントロールを行う。これがバックプレッシャーと呼ばれる。  
ノードはネットワークリンクや受け手のノードのオーバーロードを回避するために、自身の送信レートを制限する。  
ここでもキュー。  
送りてがネットワークにデータを送る前にキューしてるということ。

* さらに、TCPは、タイムアウトまでに ACK が得られなかった場合、パケットがロストしたと判断する。  
上記は ラウンドトリップの時間から計算される。  
ロストしたパケットは自動的に再送信される
* アプリ側はパケットロスと再送信自体を見ることはできないが、結果としての遅延時間を見ることはできる。
(タイムアウトが執行するのを待ち、再送信パケットが ACK されるのを待つ)

## TCP Versus UDP
-------------------------------------------------
* レイテンシーにセンシティブなアプリ(ビデオ会議やVOIP)は、TCPではなくUDPを使う。
* そこには reliability and variability of delays のトレードオフがある。
* UDP はフローコントロールを行わないし、ロストパケットを再送信しない
* it avoids some of the reasons for variable network delays (although it is still susceptible to switch queues and scheduling delays).
* UDP は、遅延したデータに価値がない場合に Good Choice となる。
* 例えばVOIP の場合、話している最中にロストしたパケットを再送信する時間はない
* この場合、再送信はされず、アプリ側でパケットが失われたスロットはサイレンスで埋める
* で、つぎのストリームに移る
* 再送は、the human layer で行われる。「もう一度おっしゃっていただけます？」
-------------------------------------------------

#### パブリッククラウドでは
* In public clouds and multi-tenant datacenters,  
resources are shared among many customers:  
the network links and switches, and even each machine’s network interface and CPUs   
(when running on virtual machines), are shared.

* Batch workloads such as MapReduce can easily saturate network links.
* As you have no control over or insight into other customers’ usage of the shared resources,
  network delays can be highly variable if someone near you (a noisy neighbor) is using a lot of resources

* In such environments, you can only choose timeouts experimentally:   
* measure the distribution of network round-trip times over an extended period,   
and over many machines, to determine the expected variability of delays. Then, taking into account your application’s characteristics, you can determine an appropriate trade-off between failure detection delay and risk of premature timeouts.
Even better, rather than using configured constant timeouts, systems can continually measure response times and their variability (jitter), and automatically adjust time‐ outs according to the observed response time distribution. This can be done with a Phi Accrual failure detector [30], which is used for example in Akka and Cassandra [31]. TCP retransmission timeouts also work similarly [27].
